{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CIFAR-10 Dataset: 171MB [08:44, 325kB/s]                                       \n"
     ]
    }
   ],
   "source": [
    "# Image Classification\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "\n",
    "def _load_label_names():\n",
    "    \"\"\"\n",
    "    Load the label names from file\n",
    "    \"\"\"\n",
    "    return ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "\n",
    "def load_cfar10_batch(cifar10_dataset_folder_path, batch_id):\n",
    "    \"\"\"\n",
    "    Load a batch of the dataset\n",
    "    \"\"\"\n",
    "    with open(cifar10_dataset_folder_path + '/data_batch_' + str(batch_id), mode='rb') as file:\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "\n",
    "    # total_features*RGB*H*W\n",
    "    features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1) #(len, 32, 32, 3)\n",
    "    labels = batch['labels']\n",
    "    \n",
    "#     print(batch['data'])\n",
    "#     print(\"-\"*80)\n",
    "#     print(batch['data'].reshape((len(batch['data']), 3, 32, 32)))\n",
    "#     print(\"-\"*80)\n",
    "#     print(features)\n",
    "#     print(\"-\"*80)\n",
    "#     print(labels)\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def display_stats(cifar10_dataset_folder_path, batch_id, sample_id):\n",
    "    \"\"\"\n",
    "    Display Stats of the the dataset\n",
    "    \"\"\"\n",
    "    batch_ids = list(range(1, 6))\n",
    "\n",
    "    if batch_id not in batch_ids:\n",
    "        print('Batch Id out of Range. Possible Batch Ids: {}'.format(batch_ids))\n",
    "        return None\n",
    "\n",
    "    features, labels = load_cfar10_batch(cifar10_dataset_folder_path, batch_id)\n",
    "\n",
    "    if not (0 <= sample_id < len(features)):\n",
    "        print('{} samples in batch {}.  {} is out of range.'.format(len(features), batch_id, sample_id))\n",
    "        return None\n",
    "\n",
    "    print('\\nStats of batch {}:'.format(batch_id))\n",
    "    print('Samples: {}'.format(len(features)))\n",
    "    print('Label Counts: {}'.format(dict(zip(*np.unique(labels, return_counts=True)))))\n",
    "    print('First 20 Labels: {}'.format(labels[:20]))\n",
    "\n",
    "    sample_image = features[sample_id]\n",
    "    sample_label = labels[sample_id]\n",
    "    label_names = _load_label_names()\n",
    "\n",
    "    print('\\nExample of Image {}:'.format(sample_id))\n",
    "    print('Image - Min Value: {} Max Value: {}'.format(sample_image.min(), sample_image.max()))\n",
    "    print('Image - Shape: {}'.format(sample_image.shape))\n",
    "    print('Label - Label Id: {} Name: {}'.format(sample_label, label_names[sample_label]))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def _preprocess_and_save(normalize, one_hot_encode, features, labels, filename):\n",
    "    \"\"\"\n",
    "    Preprocess data and save it to file\n",
    "    \"\"\"\n",
    "    features = normalize(features)\n",
    "    labels = one_hot_encode(labels)\n",
    "\n",
    "    pickle.dump((features, labels), open(filename, 'wb'))\n",
    "\n",
    "\n",
    "def preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode):\n",
    "    \"\"\"\n",
    "    Preprocess Training and Validation Data\n",
    "    \"\"\"\n",
    "    n_batches = 5\n",
    "    valid_features = []\n",
    "    valid_labels = []\n",
    "\n",
    "    for batch_i in range(1, n_batches + 1):\n",
    "        features, labels = load_cfar10_batch(cifar10_dataset_folder_path, batch_i)\n",
    "        validation_count = int(len(features) * 0.1) #10%\n",
    "\n",
    "        # Prprocess and save a batch of training data\n",
    "        _preprocess_and_save(\n",
    "            normalize,\n",
    "            one_hot_encode,\n",
    "            features[:-validation_count],\n",
    "            labels[:-validation_count],\n",
    "            'preprocess_batch_' + str(batch_i) + '.p')\n",
    "\n",
    "        # Use a portion of training batch for validation\n",
    "        valid_features.extend(features[-validation_count:])\n",
    "        valid_labels.extend(labels[-validation_count:])\n",
    "\n",
    "    # Preprocess and Save all validation data\n",
    "    _preprocess_and_save(\n",
    "        normalize,\n",
    "        one_hot_encode,\n",
    "        np.array(valid_features),\n",
    "        np.array(valid_labels),\n",
    "        'preprocess_validation.p')\n",
    "\n",
    "    with open(cifar10_dataset_folder_path + '/test_batch', mode='rb') as file:\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "\n",
    "    # load the test data\n",
    "    test_features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    test_labels = batch['labels']\n",
    "\n",
    "    # Preprocess and Save all test data\n",
    "    _preprocess_and_save(\n",
    "        normalize,\n",
    "        one_hot_encode,\n",
    "        np.array(test_features),\n",
    "        np.array(test_labels),\n",
    "        'preprocess_testing.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def batch_features_labels(features, labels, batch_size):\n",
    "    \"\"\"\n",
    "    Split features and labels into batches\n",
    "    \"\"\"\n",
    "    for start in range(0, len(features), batch_size):\n",
    "        end = min(start + batch_size, len(features))\n",
    "        yield features[start:end], labels[start:end]\n",
    "\n",
    "\n",
    "def load_preprocess_training_batch(batch_id, batch_size):\n",
    "    \"\"\"\n",
    "    Load the Preprocessed Training data and return them in batches of <batch_size> or less\n",
    "    \"\"\"\n",
    "    filename = 'preprocess_batch_' + str(batch_id) + '.p'\n",
    "    features, labels = pickle.load(open(filename, mode='rb'))\n",
    "\n",
    "    # Return the training data in batches of size <batch_size> or less\n",
    "    return batch_features_labels(features, labels, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_image_predictions(features, labels, predictions):\n",
    "    n_classes = 10\n",
    "    label_names = _load_label_names()\n",
    "    label_binarizer = LabelBinarizer()\n",
    "    label_binarizer.fit(range(n_classes))\n",
    "    label_ids = label_binarizer.inverse_transform(np.array(labels))\n",
    "\n",
    "    fig, axies = plt.subplots(nrows=4, ncols=2)\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle('Softmax Predictions', fontsize=20, y=1.1)\n",
    "\n",
    "    n_predictions = 5\n",
    "    margin = 0.05\n",
    "    ind = np.arange(n_predictions)\n",
    "    width = (1. - 2. * margin) / n_predictions\n",
    "\n",
    "    for image_i, (feature, label_id, pred_indicies, pred_values) in enumerate(zip(features, label_ids, predictions.indices, predictions.values)):\n",
    "        pred_names = [label_names[pred_i] for pred_i in pred_indicies]\n",
    "        correct_name = label_names[label_id]\n",
    "\n",
    "        axies[image_i][0].imshow(feature*255)\n",
    "        axies[image_i][0].set_title(correct_name)\n",
    "        axies[image_i][0].set_axis_off()\n",
    "\n",
    "        axies[image_i][1].barh(ind + margin, pred_values[::-1], width)\n",
    "        axies[image_i][1].set_yticks(ind + margin)\n",
    "        axies[image_i][1].set_yticklabels(pred_names[::-1])\n",
    "        axies[image_i][1].set_xticks([0, 0.5, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 5:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1014, 1: 1014, 2: 952, 3: 1016, 4: 997, 5: 1025, 6: 980, 7: 977, 8: 1003, 9: 1022}\n",
      "First 20 Labels: [1, 8, 5, 1, 5, 7, 4, 3, 8, 2, 7, 2, 0, 1, 5, 9, 6, 2, 0, 8]\n",
      "\n",
      "Example of Image 100:\n",
      "Image - Min Value: 5 Max Value: 255\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 9 Name: truck\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 5 #1-5\n",
    "sample_id = 100 #1-10,000\n",
    "display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Min-Max normalizer\n",
    "# z-normalizer (not using now)\n",
    "\n",
    "import numpy as np\n",
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    x = np.array(x)\n",
    "    x_max = np.max(x)\n",
    "    x_min = np.min(x)\n",
    "    output = (x - x_min)/(x_max - x_min)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(range(10))\n",
    "\n",
    "\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    #print(lb.transform(x))\n",
    "    return lb.transform(x) #0-9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 0.54901961,  0.49019608,  0.45098039],\n",
       "         [ 0.57254902,  0.50980392,  0.47843137],\n",
       "         [ 0.56078431,  0.49803922,  0.47843137],\n",
       "         ..., \n",
       "         [ 0.66666667,  0.56862745,  0.51372549],\n",
       "         [ 0.69019608,  0.58823529,  0.5254902 ],\n",
       "         [ 0.66666667,  0.57647059,  0.52156863]],\n",
       " \n",
       "        [[ 0.4745098 ,  0.42352941,  0.50588235],\n",
       "         [ 0.50980392,  0.4627451 ,  0.54509804],\n",
       "         [ 0.5254902 ,  0.4745098 ,  0.56078431],\n",
       "         ..., \n",
       "         [ 0.63921569,  0.55294118,  0.61568627],\n",
       "         [ 0.66666667,  0.57254902,  0.63137255],\n",
       "         [ 0.66666667,  0.58039216,  0.63137255]],\n",
       " \n",
       "        [[ 0.59607843,  0.54509804,  0.68235294],\n",
       "         [ 0.61568627,  0.56862745,  0.70196078],\n",
       "         [ 0.60784314,  0.56078431,  0.68627451],\n",
       "         ..., \n",
       "         [ 0.69411765,  0.60392157,  0.75686275],\n",
       "         [ 0.70980392,  0.61176471,  0.76078431],\n",
       "         [ 0.71764706,  0.62745098,  0.76078431]],\n",
       " \n",
       "        ..., \n",
       "        [[ 0.49019608,  0.43137255,  0.4       ],\n",
       "         [ 0.50588235,  0.43921569,  0.40392157],\n",
       "         [ 0.29803922,  0.2627451 ,  0.18431373],\n",
       "         ..., \n",
       "         [ 0.65882353,  0.5372549 ,  0.47058824],\n",
       "         [ 0.61960784,  0.49411765,  0.40392157],\n",
       "         [ 0.57254902,  0.45490196,  0.34117647]],\n",
       " \n",
       "        [[ 0.33333333,  0.30196078,  0.2745098 ],\n",
       "         [ 0.36862745,  0.31764706,  0.27843137],\n",
       "         [ 0.29019608,  0.25490196,  0.17647059],\n",
       "         ..., \n",
       "         [ 0.63529412,  0.51764706,  0.41568627],\n",
       "         [ 0.65098039,  0.5254902 ,  0.39215686],\n",
       "         [ 0.61960784,  0.50196078,  0.36078431]],\n",
       " \n",
       "        [[ 0.49019608,  0.43921569,  0.43529412],\n",
       "         [ 0.50980392,  0.44313725,  0.43529412],\n",
       "         [ 0.41176471,  0.35686275,  0.29411765],\n",
       "         ..., \n",
       "         [ 0.51764706,  0.41568627,  0.30588235],\n",
       "         [ 0.50980392,  0.39607843,  0.25098039],\n",
       "         [ 0.55686275,  0.45098039,  0.30588235]]]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_features[0], valid_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a bach of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32, shape = (None, image_shape[0], image_shape[1], image_shape[2]), name = 'x')\n",
    "    # None indicates that the first dimension, corresponding to the batch size, can be of any size.\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32, shape = (None, n_classes), name = 'y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32, shape = (None), name = 'keep_prob')\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    shape_of_x_tensor = x_tensor.get_shape().as_list()\n",
    "    F_W = tf.Variable(tf.truncated_normal([conv_ksize[0] ,conv_ksize[1] ,shape_of_x_tensor[-1] ,conv_num_outputs] \n",
    "                                          ,dtype=tf.float32, stddev=0.2))\n",
    "    F_b = tf.Variable(tf.zeros([conv_num_outputs]  ,dtype=tf.float32))\n",
    "    \n",
    "    strides_conv = [1, conv_strides[0], conv_strides[1], 1]\n",
    "    padding = 'SAME' #or VALID\n",
    "    \n",
    "    output = tf.nn.conv2d(x_tensor, F_W, strides_conv, padding)\n",
    "    output = tf.nn.bias_add(output, F_b)\n",
    "    \n",
    "    output = tf.nn.relu(output)\n",
    "    \n",
    "    #pooling\n",
    "    ksize_maxpool = [1, pool_ksize[0], pool_ksize[1], 1]\n",
    "    strides_maxpool = [1, pool_strides[0], pool_strides[1], 1]\n",
    "    output = tf.nn.max_pool(output, ksize_maxpool, strides_maxpool, padding)\n",
    "    \n",
    "    return output \n",
    "\n",
    "\n",
    "#https://stackoverflow.com/questions/34642595/tensorflow-strides-argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    shape = x_tensor.get_shape().as_list()\n",
    "    flat_dim = shape[1]*shape[2]*shape[3]\n",
    "    output = tf.reshape(x_tensor, [-1, flat_dim])\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    shape = x_tensor.get_shape().as_list()\n",
    "    weights= tf.Variable( tf.truncated_normal([shape[1], num_outputs] ,dtype=tf.float32, stddev=0.2))\n",
    "    biases = tf.Variable(tf.zeros([num_outputs]  ,dtype=tf.float32))\n",
    "    \n",
    "    out = tf.add(tf.matmul(x_tensor, weights), biases)\n",
    "    out = tf.nn.relu(out)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    shape = x_tensor.get_shape().as_list()\n",
    "    weights= tf.Variable(tf.truncated_normal([shape[1], num_outputs] ,dtype=tf.float32, stddev=0.2))\n",
    "    biases = tf.Variable(tf.zeros([num_outputs]  ,dtype=tf.float32))\n",
    "    out = tf.add(tf.matmul(x_tensor, weights), biases)\n",
    "    # No Activation function\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-20-5b3d1c709121>:49: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "\n",
    "    out = conv2d_maxpool(x, conv_num_outputs = 16, conv_ksize = (3,3), conv_strides = (1,1), pool_ksize=(2,2), pool_strides=(2,2))\n",
    "    out = conv2d_maxpool(out, conv_num_outputs = 32, conv_ksize = (3,3), conv_strides = (1,1), pool_ksize=(2,2), pool_strides=(2,2))\n",
    "    out = conv2d_maxpool(out, conv_num_outputs = 64, conv_ksize = (3,3), conv_strides = (1,1), pool_ksize=(2,2), pool_strides=(2,2))\n",
    "\n",
    "    # Function Definition from Above:\n",
    "    out = flatten(out)\n",
    "    \n",
    "\n",
    "    out = fully_conn(out, num_outputs = 64)\n",
    "    out = tf.nn.dropout(out, keep_prob)\n",
    "    out = fully_conn(out, num_outputs = 32)\n",
    "    out = tf.nn.dropout(out, keep_prob)\n",
    "    out = fully_conn(out, num_outputs = 16)\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    \n",
    "    out = output(out, num_outputs = 10)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Input placeholders\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost) #GD, SGD\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    session.run(optimizer, feed_dict={x:feature_batch, y:label_batch,keep_prob:keep_probability})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    valid_acc = sess.run(accuracy, feed_dict={\n",
    "                x: valid_features,\n",
    "                y: valid_labels,\n",
    "                keep_prob: 1.})\n",
    "    train_acc = sess.run(accuracy, feed_dict={\n",
    "                x: feature_batch,\n",
    "                y: label_batch,\n",
    "                keep_prob: 1.})\n",
    "    train_cost = sess.run(cost, feed_dict={\n",
    "                x: feature_batch,\n",
    "                y: label_batch,\n",
    "                keep_prob: 1.})\n",
    "    print('Cost {::>8.5f}, Accuracy on Training {:.4f} -'\n",
    "                  'Validation Accuracy: {:.4f}'.format(\n",
    "                train_cost,\n",
    "                train_acc,\n",
    "                valid_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 50 # 100\n",
    "batch_size = 256  #(2^n): 512, \n",
    "keep_probability = 0.6 #0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Cost :2.28436, Accuracy on Training 0.0750 -Validation Accuracy: 0.1382\n",
      "Epoch  2, CIFAR-10 Batch 1:  Cost :2.26228, Accuracy on Training 0.0750 -Validation Accuracy: 0.1602\n",
      "Epoch  3, CIFAR-10 Batch 1:  Cost :2.23938, Accuracy on Training 0.1750 -Validation Accuracy: 0.1804\n",
      "Epoch  4, CIFAR-10 Batch 1:  Cost :2.17705, Accuracy on Training 0.1250 -Validation Accuracy: 0.1856\n",
      "Epoch  5, CIFAR-10 Batch 1:  Cost :2.10798, Accuracy on Training 0.1250 -Validation Accuracy: 0.2064\n",
      "Epoch  6, CIFAR-10 Batch 1:  Cost :2.05124, Accuracy on Training 0.2500 -Validation Accuracy: 0.2554\n",
      "Epoch  7, CIFAR-10 Batch 1:  Cost :2.00166, Accuracy on Training 0.2750 -Validation Accuracy: 0.2718\n",
      "Epoch  8, CIFAR-10 Batch 1:  Cost :1.97618, Accuracy on Training 0.3000 -Validation Accuracy: 0.2938\n",
      "Epoch  9, CIFAR-10 Batch 1:  Cost :1.92320, Accuracy on Training 0.3500 -Validation Accuracy: 0.3032\n",
      "Epoch 10, CIFAR-10 Batch 1:  Cost :1.91678, Accuracy on Training 0.3000 -Validation Accuracy: 0.3122\n",
      "Epoch 11, CIFAR-10 Batch 1:  Cost :1.86652, Accuracy on Training 0.2750 -Validation Accuracy: 0.3192\n",
      "Epoch 12, CIFAR-10 Batch 1:  Cost :1.81684, Accuracy on Training 0.3250 -Validation Accuracy: 0.3252\n",
      "Epoch 13, CIFAR-10 Batch 1:  Cost :1.77704, Accuracy on Training 0.4500 -Validation Accuracy: 0.3432\n",
      "Epoch 14, CIFAR-10 Batch 1:  Cost :1.79282, Accuracy on Training 0.4250 -Validation Accuracy: 0.3426\n",
      "Epoch 15, CIFAR-10 Batch 1:  Cost :1.74061, Accuracy on Training 0.4000 -Validation Accuracy: 0.3484\n",
      "Epoch 16, CIFAR-10 Batch 1:  Cost :1.65767, Accuracy on Training 0.4000 -Validation Accuracy: 0.3612\n",
      "Epoch 17, CIFAR-10 Batch 1:  Cost :1.61667, Accuracy on Training 0.4000 -Validation Accuracy: 0.3736\n",
      "Epoch 18, CIFAR-10 Batch 1:  Cost :1.57420, Accuracy on Training 0.4000 -Validation Accuracy: 0.3824\n",
      "Epoch 19, CIFAR-10 Batch 1:  Cost :1.53371, Accuracy on Training 0.4250 -Validation Accuracy: 0.3930\n",
      "Epoch 20, CIFAR-10 Batch 1:  Cost :1.52368, Accuracy on Training 0.4750 -Validation Accuracy: 0.3876\n",
      "Epoch 21, CIFAR-10 Batch 1:  Cost :1.39826, Accuracy on Training 0.4750 -Validation Accuracy: 0.4142\n",
      "Epoch 22, CIFAR-10 Batch 1:  Cost :1.40088, Accuracy on Training 0.5000 -Validation Accuracy: 0.3954\n",
      "Epoch 23, CIFAR-10 Batch 1:  Cost :1.35840, Accuracy on Training 0.5000 -Validation Accuracy: 0.4232\n",
      "Epoch 24, CIFAR-10 Batch 1:  Cost :1.32165, Accuracy on Training 0.5750 -Validation Accuracy: 0.4164\n",
      "Epoch 25, CIFAR-10 Batch 1:  Cost :1.29242, Accuracy on Training 0.5250 -Validation Accuracy: 0.4196\n",
      "Epoch 26, CIFAR-10 Batch 1:  Cost :1.27647, Accuracy on Training 0.5500 -Validation Accuracy: 0.4346\n",
      "Epoch 27, CIFAR-10 Batch 1:  Cost :1.21361, Accuracy on Training 0.5750 -Validation Accuracy: 0.4418\n",
      "Epoch 28, CIFAR-10 Batch 1:  Cost :1.22641, Accuracy on Training 0.6000 -Validation Accuracy: 0.4348\n",
      "Epoch 29, CIFAR-10 Batch 1:  Cost :1.18004, Accuracy on Training 0.5500 -Validation Accuracy: 0.4456\n",
      "Epoch 30, CIFAR-10 Batch 1:  Cost :1.14502, Accuracy on Training 0.5750 -Validation Accuracy: 0.4486\n",
      "Epoch 31, CIFAR-10 Batch 1:  Cost :1.11682, Accuracy on Training 0.6500 -Validation Accuracy: 0.4610\n",
      "Epoch 32, CIFAR-10 Batch 1:  Cost :1.14344, Accuracy on Training 0.6000 -Validation Accuracy: 0.4344\n",
      "Epoch 33, CIFAR-10 Batch 1:  Cost :1.06420, Accuracy on Training 0.6000 -Validation Accuracy: 0.4496\n",
      "Epoch 34, CIFAR-10 Batch 1:  Cost :1.06622, Accuracy on Training 0.6000 -Validation Accuracy: 0.4436\n",
      "Epoch 35, CIFAR-10 Batch 1:  Cost :1.06947, Accuracy on Training 0.5750 -Validation Accuracy: 0.4410\n",
      "Epoch 36, CIFAR-10 Batch 1:  Cost :1.05331, Accuracy on Training 0.6000 -Validation Accuracy: 0.4288\n",
      "Epoch 37, CIFAR-10 Batch 1:  Cost :1.03614, Accuracy on Training 0.6750 -Validation Accuracy: 0.4608\n",
      "Epoch 38, CIFAR-10 Batch 1:  Cost :0.95291, Accuracy on Training 0.6750 -Validation Accuracy: 0.4506\n",
      "Epoch 39, CIFAR-10 Batch 1:  Cost :0.96018, Accuracy on Training 0.6750 -Validation Accuracy: 0.4714\n",
      "Epoch 40, CIFAR-10 Batch 1:  Cost :0.92681, Accuracy on Training 0.6750 -Validation Accuracy: 0.4752\n",
      "Epoch 41, CIFAR-10 Batch 1:  Cost :0.98059, Accuracy on Training 0.7000 -Validation Accuracy: 0.4646\n",
      "Epoch 42, CIFAR-10 Batch 1:  Cost :0.92791, Accuracy on Training 0.6000 -Validation Accuracy: 0.4676\n",
      "Epoch 43, CIFAR-10 Batch 1:  Cost :0.89273, Accuracy on Training 0.6750 -Validation Accuracy: 0.4834\n",
      "Epoch 44, CIFAR-10 Batch 1:  Cost :0.86862, Accuracy on Training 0.6500 -Validation Accuracy: 0.4856\n",
      "Epoch 45, CIFAR-10 Batch 1:  Cost :0.84814, Accuracy on Training 0.6250 -Validation Accuracy: 0.4812\n",
      "Epoch 46, CIFAR-10 Batch 1:  Cost :0.85146, Accuracy on Training 0.7250 -Validation Accuracy: 0.4848\n",
      "Epoch 47, CIFAR-10 Batch 1:  Cost :0.85032, Accuracy on Training 0.7000 -Validation Accuracy: 0.4822\n",
      "Epoch 48, CIFAR-10 Batch 1:  Cost :0.82290, Accuracy on Training 0.7250 -Validation Accuracy: 0.4854\n",
      "Epoch 49, CIFAR-10 Batch 1:  Cost :0.79139, Accuracy on Training 0.7000 -Validation Accuracy: 0.5004\n",
      "Epoch 50, CIFAR-10 Batch 1:  Cost :0.76806, Accuracy on Training 0.7000 -Validation Accuracy: 0.4818\n"
     ]
    }
   ],
   "source": [
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Cost :2.29053, Accuracy on Training 0.2750 -Validation Accuracy: 0.1210\n",
      "Epoch  1, CIFAR-10 Batch 2:  Cost :2.29741, Accuracy on Training 0.1000 -Validation Accuracy: 0.1426\n",
      "Epoch  1, CIFAR-10 Batch 3:  Cost :2.26359, Accuracy on Training 0.2000 -Validation Accuracy: 0.1860\n",
      "Epoch  1, CIFAR-10 Batch 4:  Cost :2.17990, Accuracy on Training 0.2750 -Validation Accuracy: 0.2202\n",
      "Epoch  1, CIFAR-10 Batch 5:  Cost :2.12064, Accuracy on Training 0.1500 -Validation Accuracy: 0.2224\n",
      "Epoch  2, CIFAR-10 Batch 1:  Cost :2.15394, Accuracy on Training 0.2500 -Validation Accuracy: 0.2232\n",
      "Epoch  2, CIFAR-10 Batch 2:  Cost :1.99807, Accuracy on Training 0.1250 -Validation Accuracy: 0.2706\n",
      "Epoch  2, CIFAR-10 Batch 3:  Cost :1.79797, Accuracy on Training 0.2750 -Validation Accuracy: 0.2458\n",
      "Epoch  2, CIFAR-10 Batch 4:  Cost :1.87469, Accuracy on Training 0.3000 -Validation Accuracy: 0.2590\n",
      "Epoch  2, CIFAR-10 Batch 5:  Cost :1.79664, Accuracy on Training 0.2750 -Validation Accuracy: 0.2794\n",
      "Epoch  3, CIFAR-10 Batch 1:  Cost :2.06040, Accuracy on Training 0.3000 -Validation Accuracy: 0.3048\n",
      "Epoch  3, CIFAR-10 Batch 2:  Cost :1.92474, Accuracy on Training 0.2250 -Validation Accuracy: 0.3210\n",
      "Epoch  3, CIFAR-10 Batch 3:  Cost :1.57031, Accuracy on Training 0.5250 -Validation Accuracy: 0.3292\n",
      "Epoch  3, CIFAR-10 Batch 4:  Cost :1.79728, Accuracy on Training 0.3500 -Validation Accuracy: 0.3406\n",
      "Epoch  3, CIFAR-10 Batch 5:  Cost :1.66166, Accuracy on Training 0.4000 -Validation Accuracy: 0.3172\n",
      "Epoch  4, CIFAR-10 Batch 1:  Cost :1.97336, Accuracy on Training 0.2500 -Validation Accuracy: 0.3482\n",
      "Epoch  4, CIFAR-10 Batch 2:  Cost :1.86650, Accuracy on Training 0.2750 -Validation Accuracy: 0.3384\n",
      "Epoch  4, CIFAR-10 Batch 3:  Cost :1.52440, Accuracy on Training 0.5000 -Validation Accuracy: 0.3574\n",
      "Epoch  4, CIFAR-10 Batch 4:  Cost :1.69499, Accuracy on Training 0.2750 -Validation Accuracy: 0.3420\n",
      "Epoch  4, CIFAR-10 Batch 5:  Cost :1.60721, Accuracy on Training 0.4000 -Validation Accuracy: 0.3622\n",
      "Epoch  5, CIFAR-10 Batch 1:  Cost :1.85786, Accuracy on Training 0.3250 -Validation Accuracy: 0.3724\n",
      "Epoch  5, CIFAR-10 Batch 2:  Cost :1.82367, Accuracy on Training 0.3500 -Validation Accuracy: 0.3788\n",
      "Epoch  5, CIFAR-10 Batch 3:  Cost :1.44482, Accuracy on Training 0.5250 -Validation Accuracy: 0.3908\n",
      "Epoch  5, CIFAR-10 Batch 4:  Cost :1.61502, Accuracy on Training 0.3750 -Validation Accuracy: 0.3960\n",
      "Epoch  5, CIFAR-10 Batch 5:  Cost :1.48772, Accuracy on Training 0.4000 -Validation Accuracy: 0.4034\n",
      "Epoch  6, CIFAR-10 Batch 1:  Cost :1.71751, Accuracy on Training 0.3000 -Validation Accuracy: 0.4022\n",
      "Epoch  6, CIFAR-10 Batch 2:  Cost :1.63270, Accuracy on Training 0.4500 -Validation Accuracy: 0.4046\n",
      "Epoch  6, CIFAR-10 Batch 3:  Cost :1.37322, Accuracy on Training 0.5500 -Validation Accuracy: 0.4140\n",
      "Epoch  6, CIFAR-10 Batch 4:  Cost :1.55447, Accuracy on Training 0.4000 -Validation Accuracy: 0.4006\n",
      "Epoch  6, CIFAR-10 Batch 5:  Cost :1.41450, Accuracy on Training 0.4750 -Validation Accuracy: 0.4310\n",
      "Epoch  7, CIFAR-10 Batch 1:  Cost :1.56401, Accuracy on Training 0.4500 -Validation Accuracy: 0.4382\n",
      "Epoch  7, CIFAR-10 Batch 2:  Cost :1.60278, Accuracy on Training 0.4750 -Validation Accuracy: 0.4292\n",
      "Epoch  7, CIFAR-10 Batch 3:  Cost :1.26203, Accuracy on Training 0.5750 -Validation Accuracy: 0.4454\n",
      "Epoch  7, CIFAR-10 Batch 4:  Cost :1.46025, Accuracy on Training 0.4250 -Validation Accuracy: 0.4356\n",
      "Epoch  7, CIFAR-10 Batch 5:  Cost :1.35828, Accuracy on Training 0.4750 -Validation Accuracy: 0.4450\n",
      "Epoch  8, CIFAR-10 Batch 1:  Cost :1.45820, Accuracy on Training 0.4000 -Validation Accuracy: 0.4572\n",
      "Epoch  8, CIFAR-10 Batch 2:  Cost :1.46616, Accuracy on Training 0.4750 -Validation Accuracy: 0.4592\n",
      "Epoch  8, CIFAR-10 Batch 3:  Cost :1.24540, Accuracy on Training 0.6250 -Validation Accuracy: 0.4712\n",
      "Epoch  8, CIFAR-10 Batch 4:  Cost :1.42031, Accuracy on Training 0.5250 -Validation Accuracy: 0.4756\n",
      "Epoch  8, CIFAR-10 Batch 5:  Cost :1.27282, Accuracy on Training 0.4750 -Validation Accuracy: 0.4762\n",
      "Epoch  9, CIFAR-10 Batch 1:  Cost :1.37662, Accuracy on Training 0.4500 -Validation Accuracy: 0.4848\n",
      "Epoch  9, CIFAR-10 Batch 2:  Cost :1.36947, Accuracy on Training 0.5250 -Validation Accuracy: 0.4814\n",
      "Epoch  9, CIFAR-10 Batch 3:  Cost :1.18581, Accuracy on Training 0.6000 -Validation Accuracy: 0.4868\n",
      "Epoch  9, CIFAR-10 Batch 4:  Cost :1.32657, Accuracy on Training 0.5250 -Validation Accuracy: 0.5020\n",
      "Epoch  9, CIFAR-10 Batch 5:  Cost :1.19321, Accuracy on Training 0.4500 -Validation Accuracy: 0.4766\n",
      "Epoch 10, CIFAR-10 Batch 1:  Cost :1.30003, Accuracy on Training 0.6250 -Validation Accuracy: 0.5036\n",
      "Epoch 10, CIFAR-10 Batch 2:  Cost :1.33012, Accuracy on Training 0.5000 -Validation Accuracy: 0.5052\n",
      "Epoch 10, CIFAR-10 Batch 3:  Cost :1.12240, Accuracy on Training 0.6250 -Validation Accuracy: 0.5104\n",
      "Epoch 10, CIFAR-10 Batch 4:  Cost :1.23645, Accuracy on Training 0.5750 -Validation Accuracy: 0.5100\n",
      "Epoch 10, CIFAR-10 Batch 5:  Cost :1.15603, Accuracy on Training 0.5500 -Validation Accuracy: 0.5060\n",
      "Epoch 11, CIFAR-10 Batch 1:  Cost :1.25254, Accuracy on Training 0.6250 -Validation Accuracy: 0.4920\n",
      "Epoch 11, CIFAR-10 Batch 2:  Cost :1.25960, Accuracy on Training 0.5250 -Validation Accuracy: 0.5246\n",
      "Epoch 11, CIFAR-10 Batch 3:  Cost :1.09706, Accuracy on Training 0.5500 -Validation Accuracy: 0.5218\n",
      "Epoch 11, CIFAR-10 Batch 4:  Cost :1.16471, Accuracy on Training 0.5000 -Validation Accuracy: 0.5364\n",
      "Epoch 11, CIFAR-10 Batch 5:  Cost :1.08313, Accuracy on Training 0.5750 -Validation Accuracy: 0.5320\n",
      "Epoch 12, CIFAR-10 Batch 1:  Cost :1.17618, Accuracy on Training 0.6250 -Validation Accuracy: 0.5336\n",
      "Epoch 12, CIFAR-10 Batch 2:  Cost :1.14407, Accuracy on Training 0.5500 -Validation Accuracy: 0.5330\n",
      "Epoch 12, CIFAR-10 Batch 3:  Cost :1.05077, Accuracy on Training 0.6500 -Validation Accuracy: 0.5410\n",
      "Epoch 12, CIFAR-10 Batch 4:  Cost :1.10811, Accuracy on Training 0.6000 -Validation Accuracy: 0.5464\n",
      "Epoch 12, CIFAR-10 Batch 5:  Cost :1.02440, Accuracy on Training 0.6500 -Validation Accuracy: 0.5374\n",
      "Epoch 13, CIFAR-10 Batch 1:  Cost :1.09761, Accuracy on Training 0.6000 -Validation Accuracy: 0.5454\n",
      "Epoch 13, CIFAR-10 Batch 2:  Cost :1.08189, Accuracy on Training 0.5500 -Validation Accuracy: 0.5524\n",
      "Epoch 13, CIFAR-10 Batch 3:  Cost :0.99872, Accuracy on Training 0.6500 -Validation Accuracy: 0.5436\n",
      "Epoch 13, CIFAR-10 Batch 4:  Cost :1.05821, Accuracy on Training 0.6000 -Validation Accuracy: 0.5686\n",
      "Epoch 13, CIFAR-10 Batch 5:  Cost :0.98899, Accuracy on Training 0.6000 -Validation Accuracy: 0.5546\n",
      "Epoch 14, CIFAR-10 Batch 1:  Cost :1.03914, Accuracy on Training 0.6750 -Validation Accuracy: 0.5392\n",
      "Epoch 14, CIFAR-10 Batch 2:  Cost :0.98620, Accuracy on Training 0.5750 -Validation Accuracy: 0.5422\n",
      "Epoch 14, CIFAR-10 Batch 3:  Cost :0.92410, Accuracy on Training 0.7750 -Validation Accuracy: 0.5612\n",
      "Epoch 14, CIFAR-10 Batch 4:  Cost :1.00995, Accuracy on Training 0.5250 -Validation Accuracy: 0.5676\n",
      "Epoch 14, CIFAR-10 Batch 5:  Cost :0.95088, Accuracy on Training 0.6000 -Validation Accuracy: 0.5540\n",
      "Epoch 15, CIFAR-10 Batch 1:  Cost :1.00266, Accuracy on Training 0.6500 -Validation Accuracy: 0.5750\n",
      "Epoch 15, CIFAR-10 Batch 2:  Cost :0.97652, Accuracy on Training 0.5750 -Validation Accuracy: 0.5786\n",
      "Epoch 15, CIFAR-10 Batch 3:  Cost :0.92484, Accuracy on Training 0.7250 -Validation Accuracy: 0.5734\n",
      "Epoch 15, CIFAR-10 Batch 4:  Cost :0.96849, Accuracy on Training 0.6000 -Validation Accuracy: 0.5736\n",
      "Epoch 15, CIFAR-10 Batch 5:  Cost :0.94012, Accuracy on Training 0.6750 -Validation Accuracy: 0.5618\n",
      "Epoch 16, CIFAR-10 Batch 1:  Cost :0.92520, Accuracy on Training 0.7000 -Validation Accuracy: 0.5844\n",
      "Epoch 16, CIFAR-10 Batch 2:  Cost :0.92078, Accuracy on Training 0.6500 -Validation Accuracy: 0.5758\n",
      "Epoch 16, CIFAR-10 Batch 3:  Cost :0.84956, Accuracy on Training 0.7000 -Validation Accuracy: 0.5648\n",
      "Epoch 16, CIFAR-10 Batch 4:  Cost :0.95528, Accuracy on Training 0.6250 -Validation Accuracy: 0.5862\n",
      "Epoch 16, CIFAR-10 Batch 5:  Cost :0.93588, Accuracy on Training 0.7250 -Validation Accuracy: 0.5622\n",
      "Epoch 17, CIFAR-10 Batch 1:  Cost :0.93378, Accuracy on Training 0.6750 -Validation Accuracy: 0.5916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, CIFAR-10 Batch 2:  Cost :0.84841, Accuracy on Training 0.7250 -Validation Accuracy: 0.5820\n",
      "Epoch 17, CIFAR-10 Batch 3:  Cost :0.81682, Accuracy on Training 0.7000 -Validation Accuracy: 0.5872\n",
      "Epoch 17, CIFAR-10 Batch 4:  Cost :0.87216, Accuracy on Training 0.6000 -Validation Accuracy: 0.5986\n",
      "Epoch 17, CIFAR-10 Batch 5:  Cost :0.89733, Accuracy on Training 0.6500 -Validation Accuracy: 0.5722\n",
      "Epoch 18, CIFAR-10 Batch 1:  Cost :0.85926, Accuracy on Training 0.7250 -Validation Accuracy: 0.5916\n",
      "Epoch 18, CIFAR-10 Batch 2:  Cost :0.76142, Accuracy on Training 0.7000 -Validation Accuracy: 0.5878\n",
      "Epoch 18, CIFAR-10 Batch 3:  Cost :0.75493, Accuracy on Training 0.7500 -Validation Accuracy: 0.5992\n",
      "Epoch 18, CIFAR-10 Batch 4:  Cost :0.85727, Accuracy on Training 0.6750 -Validation Accuracy: 0.6038\n",
      "Epoch 18, CIFAR-10 Batch 5:  Cost :0.85932, Accuracy on Training 0.6500 -Validation Accuracy: 0.5868\n",
      "Epoch 19, CIFAR-10 Batch 1:  Cost :0.84384, Accuracy on Training 0.7250 -Validation Accuracy: 0.6070\n",
      "Epoch 19, CIFAR-10 Batch 2:  Cost :0.82490, Accuracy on Training 0.7750 -Validation Accuracy: 0.5890\n",
      "Epoch 19, CIFAR-10 Batch 3:  Cost :0.71655, Accuracy on Training 0.8250 -Validation Accuracy: 0.5876\n",
      "Epoch 19, CIFAR-10 Batch 4:  Cost :0.81516, Accuracy on Training 0.6750 -Validation Accuracy: 0.6062\n",
      "Epoch 19, CIFAR-10 Batch 5:  Cost :0.82298, Accuracy on Training 0.6750 -Validation Accuracy: 0.5894\n",
      "Epoch 20, CIFAR-10 Batch 1:  Cost :0.84012, Accuracy on Training 0.7000 -Validation Accuracy: 0.6062\n",
      "Epoch 20, CIFAR-10 Batch 2:  Cost :0.72249, Accuracy on Training 0.7000 -Validation Accuracy: 0.6024\n",
      "Epoch 20, CIFAR-10 Batch 3:  Cost :0.67960, Accuracy on Training 0.7750 -Validation Accuracy: 0.5958\n",
      "Epoch 20, CIFAR-10 Batch 4:  Cost :0.79327, Accuracy on Training 0.7250 -Validation Accuracy: 0.6112\n",
      "Epoch 20, CIFAR-10 Batch 5:  Cost :0.84734, Accuracy on Training 0.6250 -Validation Accuracy: 0.5866\n",
      "Epoch 21, CIFAR-10 Batch 1:  Cost :0.77870, Accuracy on Training 0.7500 -Validation Accuracy: 0.6096\n",
      "Epoch 21, CIFAR-10 Batch 2:  Cost :0.74518, Accuracy on Training 0.7750 -Validation Accuracy: 0.6116\n",
      "Epoch 21, CIFAR-10 Batch 3:  Cost :0.63825, Accuracy on Training 0.8000 -Validation Accuracy: 0.6092\n",
      "Epoch 21, CIFAR-10 Batch 4:  Cost :0.77178, Accuracy on Training 0.7000 -Validation Accuracy: 0.6146\n",
      "Epoch 21, CIFAR-10 Batch 5:  Cost :0.76028, Accuracy on Training 0.7000 -Validation Accuracy: 0.6110\n",
      "Epoch 22, CIFAR-10 Batch 1:  Cost :0.80848, Accuracy on Training 0.7250 -Validation Accuracy: 0.6152\n",
      "Epoch 22, CIFAR-10 Batch 2:  Cost :0.69620, Accuracy on Training 0.7500 -Validation Accuracy: 0.6082\n",
      "Epoch 22, CIFAR-10 Batch 3:  Cost :0.61528, Accuracy on Training 0.8000 -Validation Accuracy: 0.6082\n",
      "Epoch 22, CIFAR-10 Batch 4:  Cost :0.80816, Accuracy on Training 0.8000 -Validation Accuracy: 0.6082\n",
      "Epoch 22, CIFAR-10 Batch 5:  Cost :0.73451, Accuracy on Training 0.7000 -Validation Accuracy: 0.5956\n",
      "Epoch 23, CIFAR-10 Batch 1:  Cost :0.79823, Accuracy on Training 0.7000 -Validation Accuracy: 0.6254\n",
      "Epoch 23, CIFAR-10 Batch 2:  Cost :0.68880, Accuracy on Training 0.7500 -Validation Accuracy: 0.6220\n",
      "Epoch 23, CIFAR-10 Batch 3:  Cost :0.61360, Accuracy on Training 0.8250 -Validation Accuracy: 0.6100\n",
      "Epoch 23, CIFAR-10 Batch 4:  Cost :0.75361, Accuracy on Training 0.7750 -Validation Accuracy: 0.6334\n",
      "Epoch 23, CIFAR-10 Batch 5:  Cost :0.69793, Accuracy on Training 0.7750 -Validation Accuracy: 0.6196\n",
      "Epoch 24, CIFAR-10 Batch 1:  Cost :0.75990, Accuracy on Training 0.7250 -Validation Accuracy: 0.6290\n",
      "Epoch 24, CIFAR-10 Batch 2:  Cost :0.68531, Accuracy on Training 0.7500 -Validation Accuracy: 0.6200\n",
      "Epoch 24, CIFAR-10 Batch 3:  Cost :0.58065, Accuracy on Training 0.8250 -Validation Accuracy: 0.6228\n",
      "Epoch 24, CIFAR-10 Batch 4:  Cost :0.71646, Accuracy on Training 0.7750 -Validation Accuracy: 0.6386\n",
      "Epoch 24, CIFAR-10 Batch 5:  Cost :0.66152, Accuracy on Training 0.8000 -Validation Accuracy: 0.6248\n",
      "Epoch 25, CIFAR-10 Batch 1:  Cost :0.72158, Accuracy on Training 0.7500 -Validation Accuracy: 0.6262\n",
      "Epoch 25, CIFAR-10 Batch 2:  Cost :0.59490, Accuracy on Training 0.8750 -Validation Accuracy: 0.6292\n",
      "Epoch 25, CIFAR-10 Batch 3:  Cost :0.57557, Accuracy on Training 0.7750 -Validation Accuracy: 0.6220\n",
      "Epoch 25, CIFAR-10 Batch 4:  Cost :0.69505, Accuracy on Training 0.8250 -Validation Accuracy: 0.6294\n",
      "Epoch 25, CIFAR-10 Batch 5:  Cost :0.63606, Accuracy on Training 0.8250 -Validation Accuracy: 0.6192\n",
      "Epoch 26, CIFAR-10 Batch 1:  Cost :0.65553, Accuracy on Training 0.7750 -Validation Accuracy: 0.6224\n",
      "Epoch 26, CIFAR-10 Batch 2:  Cost :0.58899, Accuracy on Training 0.8000 -Validation Accuracy: 0.6304\n",
      "Epoch 26, CIFAR-10 Batch 3:  Cost :0.57550, Accuracy on Training 0.8750 -Validation Accuracy: 0.6248\n",
      "Epoch 26, CIFAR-10 Batch 4:  Cost :0.71201, Accuracy on Training 0.7750 -Validation Accuracy: 0.6322\n",
      "Epoch 26, CIFAR-10 Batch 5:  Cost :0.62314, Accuracy on Training 0.8500 -Validation Accuracy: 0.6308\n",
      "Epoch 27, CIFAR-10 Batch 1:  Cost :0.69720, Accuracy on Training 0.7500 -Validation Accuracy: 0.6258\n",
      "Epoch 27, CIFAR-10 Batch 2:  Cost :0.59937, Accuracy on Training 0.8250 -Validation Accuracy: 0.6362\n",
      "Epoch 27, CIFAR-10 Batch 3:  Cost :0.57259, Accuracy on Training 0.8250 -Validation Accuracy: 0.6278\n",
      "Epoch 27, CIFAR-10 Batch 4:  Cost :0.68112, Accuracy on Training 0.8000 -Validation Accuracy: 0.6320\n",
      "Epoch 27, CIFAR-10 Batch 5:  Cost :0.63150, Accuracy on Training 0.8250 -Validation Accuracy: 0.6370\n",
      "Epoch 28, CIFAR-10 Batch 1:  Cost :0.70290, Accuracy on Training 0.7750 -Validation Accuracy: 0.6374\n",
      "Epoch 28, CIFAR-10 Batch 2:  Cost :0.60868, Accuracy on Training 0.8250 -Validation Accuracy: 0.6410\n",
      "Epoch 28, CIFAR-10 Batch 3:  Cost :0.53136, Accuracy on Training 0.8750 -Validation Accuracy: 0.6388\n",
      "Epoch 28, CIFAR-10 Batch 4:  Cost :0.68550, Accuracy on Training 0.7500 -Validation Accuracy: 0.6442\n",
      "Epoch 28, CIFAR-10 Batch 5:  Cost :0.62641, Accuracy on Training 0.8000 -Validation Accuracy: 0.6408\n",
      "Epoch 29, CIFAR-10 Batch 1:  Cost :0.67200, Accuracy on Training 0.7750 -Validation Accuracy: 0.6386\n",
      "Epoch 29, CIFAR-10 Batch 2:  Cost :0.55552, Accuracy on Training 0.8000 -Validation Accuracy: 0.6310\n",
      "Epoch 29, CIFAR-10 Batch 3:  Cost :0.51956, Accuracy on Training 0.8750 -Validation Accuracy: 0.6454\n",
      "Epoch 29, CIFAR-10 Batch 4:  Cost :0.66969, Accuracy on Training 0.8000 -Validation Accuracy: 0.6364\n",
      "Epoch 29, CIFAR-10 Batch 5:  Cost :0.60775, Accuracy on Training 0.8250 -Validation Accuracy: 0.6394\n",
      "Epoch 30, CIFAR-10 Batch 1:  Cost :0.63518, Accuracy on Training 0.8250 -Validation Accuracy: 0.6314\n",
      "Epoch 30, CIFAR-10 Batch 2:  Cost :0.55494, Accuracy on Training 0.7750 -Validation Accuracy: 0.6418\n",
      "Epoch 30, CIFAR-10 Batch 3:  Cost :0.54737, Accuracy on Training 0.8000 -Validation Accuracy: 0.6378\n",
      "Epoch 30, CIFAR-10 Batch 4:  Cost :0.59886, Accuracy on Training 0.8000 -Validation Accuracy: 0.6410\n",
      "Epoch 30, CIFAR-10 Batch 5:  Cost :0.56910, Accuracy on Training 0.8500 -Validation Accuracy: 0.6452\n",
      "Epoch 31, CIFAR-10 Batch 1:  Cost :0.61675, Accuracy on Training 0.8000 -Validation Accuracy: 0.6370\n",
      "Epoch 31, CIFAR-10 Batch 2:  Cost :0.58669, Accuracy on Training 0.8500 -Validation Accuracy: 0.6418\n",
      "Epoch 31, CIFAR-10 Batch 3:  Cost :0.48957, Accuracy on Training 0.8250 -Validation Accuracy: 0.6500\n",
      "Epoch 31, CIFAR-10 Batch 4:  Cost :0.62298, Accuracy on Training 0.8000 -Validation Accuracy: 0.6486\n",
      "Epoch 31, CIFAR-10 Batch 5:  Cost :0.53610, Accuracy on Training 0.9000 -Validation Accuracy: 0.6562\n",
      "Epoch 32, CIFAR-10 Batch 1:  Cost :0.59850, Accuracy on Training 0.8000 -Validation Accuracy: 0.6420\n",
      "Epoch 32, CIFAR-10 Batch 2:  Cost :0.49294, Accuracy on Training 0.8500 -Validation Accuracy: 0.6366\n",
      "Epoch 32, CIFAR-10 Batch 3:  Cost :0.49001, Accuracy on Training 0.8250 -Validation Accuracy: 0.6356\n",
      "Epoch 32, CIFAR-10 Batch 4:  Cost :0.60331, Accuracy on Training 0.7750 -Validation Accuracy: 0.6508\n",
      "Epoch 32, CIFAR-10 Batch 5:  Cost :0.53072, Accuracy on Training 0.8500 -Validation Accuracy: 0.6460\n",
      "Epoch 33, CIFAR-10 Batch 1:  Cost :0.62026, Accuracy on Training 0.7750 -Validation Accuracy: 0.6472\n",
      "Epoch 33, CIFAR-10 Batch 2:  Cost :0.51708, Accuracy on Training 0.8500 -Validation Accuracy: 0.6582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, CIFAR-10 Batch 3:  Cost :0.51265, Accuracy on Training 0.8750 -Validation Accuracy: 0.6456\n",
      "Epoch 33, CIFAR-10 Batch 4:  Cost :0.55950, Accuracy on Training 0.7750 -Validation Accuracy: 0.6570\n",
      "Epoch 33, CIFAR-10 Batch 5:  Cost :0.52119, Accuracy on Training 0.8750 -Validation Accuracy: 0.6520\n",
      "Epoch 34, CIFAR-10 Batch 1:  Cost :0.64201, Accuracy on Training 0.7750 -Validation Accuracy: 0.6544\n",
      "Epoch 34, CIFAR-10 Batch 2:  Cost :0.48167, Accuracy on Training 0.9000 -Validation Accuracy: 0.6614\n",
      "Epoch 34, CIFAR-10 Batch 3:  Cost :0.43921, Accuracy on Training 0.8750 -Validation Accuracy: 0.6480\n",
      "Epoch 34, CIFAR-10 Batch 4:  Cost :0.57709, Accuracy on Training 0.8000 -Validation Accuracy: 0.6384\n",
      "Epoch 34, CIFAR-10 Batch 5:  Cost :0.50573, Accuracy on Training 0.9250 -Validation Accuracy: 0.6620\n",
      "Epoch 35, CIFAR-10 Batch 1:  Cost :0.58283, Accuracy on Training 0.8000 -Validation Accuracy: 0.6540\n",
      "Epoch 35, CIFAR-10 Batch 2:  Cost :0.48030, Accuracy on Training 0.8500 -Validation Accuracy: 0.6434\n",
      "Epoch 35, CIFAR-10 Batch 3:  Cost :0.41037, Accuracy on Training 0.8750 -Validation Accuracy: 0.6570\n",
      "Epoch 35, CIFAR-10 Batch 4:  Cost :0.54642, Accuracy on Training 0.8250 -Validation Accuracy: 0.6542\n",
      "Epoch 35, CIFAR-10 Batch 5:  Cost :0.49437, Accuracy on Training 0.9000 -Validation Accuracy: 0.6596\n",
      "Epoch 36, CIFAR-10 Batch 1:  Cost :0.63279, Accuracy on Training 0.7500 -Validation Accuracy: 0.6524\n",
      "Epoch 36, CIFAR-10 Batch 2:  Cost :0.40785, Accuracy on Training 0.8500 -Validation Accuracy: 0.6538\n",
      "Epoch 36, CIFAR-10 Batch 3:  Cost :0.40884, Accuracy on Training 0.9250 -Validation Accuracy: 0.6600\n",
      "Epoch 36, CIFAR-10 Batch 4:  Cost :0.53981, Accuracy on Training 0.8750 -Validation Accuracy: 0.6414\n",
      "Epoch 36, CIFAR-10 Batch 5:  Cost :0.49240, Accuracy on Training 0.9000 -Validation Accuracy: 0.6608\n",
      "Epoch 37, CIFAR-10 Batch 1:  Cost :0.56726, Accuracy on Training 0.8000 -Validation Accuracy: 0.6544\n",
      "Epoch 37, CIFAR-10 Batch 2:  Cost :0.46237, Accuracy on Training 0.8500 -Validation Accuracy: 0.6646\n",
      "Epoch 37, CIFAR-10 Batch 3:  Cost :0.40603, Accuracy on Training 0.9250 -Validation Accuracy: 0.6554\n",
      "Epoch 37, CIFAR-10 Batch 4:  Cost :0.49612, Accuracy on Training 0.8750 -Validation Accuracy: 0.6564\n",
      "Epoch 37, CIFAR-10 Batch 5:  Cost :0.47511, Accuracy on Training 0.9250 -Validation Accuracy: 0.6634\n",
      "Epoch 38, CIFAR-10 Batch 1:  Cost :0.57629, Accuracy on Training 0.7500 -Validation Accuracy: 0.6472\n",
      "Epoch 38, CIFAR-10 Batch 2:  Cost :0.38919, Accuracy on Training 0.9000 -Validation Accuracy: 0.6630\n",
      "Epoch 38, CIFAR-10 Batch 3:  Cost :0.41986, Accuracy on Training 0.9000 -Validation Accuracy: 0.6580\n",
      "Epoch 38, CIFAR-10 Batch 4:  Cost :0.50929, Accuracy on Training 0.8000 -Validation Accuracy: 0.6526\n",
      "Epoch 38, CIFAR-10 Batch 5:  Cost :0.45204, Accuracy on Training 0.9250 -Validation Accuracy: 0.6610\n",
      "Epoch 39, CIFAR-10 Batch 1:  Cost :0.54063, Accuracy on Training 0.8000 -Validation Accuracy: 0.6648\n",
      "Epoch 39, CIFAR-10 Batch 2:  Cost :0.37936, Accuracy on Training 0.9500 -Validation Accuracy: 0.6612\n",
      "Epoch 39, CIFAR-10 Batch 3:  Cost :0.35197, Accuracy on Training 0.9250 -Validation Accuracy: 0.6716\n",
      "Epoch 39, CIFAR-10 Batch 4:  Cost :0.47992, Accuracy on Training 0.8500 -Validation Accuracy: 0.6602\n",
      "Epoch 39, CIFAR-10 Batch 5:  Cost :0.44708, Accuracy on Training 0.9250 -Validation Accuracy: 0.6614\n",
      "Epoch 40, CIFAR-10 Batch 1:  Cost :0.57891, Accuracy on Training 0.7750 -Validation Accuracy: 0.6492\n",
      "Epoch 40, CIFAR-10 Batch 2:  Cost :0.39522, Accuracy on Training 0.9000 -Validation Accuracy: 0.6622\n",
      "Epoch 40, CIFAR-10 Batch 3:  Cost :0.38267, Accuracy on Training 0.9250 -Validation Accuracy: 0.6606\n",
      "Epoch 40, CIFAR-10 Batch 4:  Cost :0.47075, Accuracy on Training 0.8500 -Validation Accuracy: 0.6642\n",
      "Epoch 40, CIFAR-10 Batch 5:  Cost :0.43199, Accuracy on Training 0.9500 -Validation Accuracy: 0.6728\n",
      "Epoch 41, CIFAR-10 Batch 1:  Cost :0.53814, Accuracy on Training 0.8000 -Validation Accuracy: 0.6562\n",
      "Epoch 41, CIFAR-10 Batch 2:  Cost :0.40453, Accuracy on Training 0.8750 -Validation Accuracy: 0.6478\n",
      "Epoch 41, CIFAR-10 Batch 3:  Cost :0.35651, Accuracy on Training 0.9500 -Validation Accuracy: 0.6652\n",
      "Epoch 41, CIFAR-10 Batch 4:  Cost :0.45007, Accuracy on Training 0.8750 -Validation Accuracy: 0.6690\n",
      "Epoch 41, CIFAR-10 Batch 5:  Cost :0.38902, Accuracy on Training 0.9250 -Validation Accuracy: 0.6670\n",
      "Epoch 42, CIFAR-10 Batch 1:  Cost :0.55237, Accuracy on Training 0.8000 -Validation Accuracy: 0.6460\n",
      "Epoch 42, CIFAR-10 Batch 2:  Cost :0.40674, Accuracy on Training 0.8750 -Validation Accuracy: 0.6366\n",
      "Epoch 42, CIFAR-10 Batch 3:  Cost :0.35425, Accuracy on Training 0.9500 -Validation Accuracy: 0.6670\n",
      "Epoch 42, CIFAR-10 Batch 4:  Cost :0.42579, Accuracy on Training 0.9500 -Validation Accuracy: 0.6648\n",
      "Epoch 42, CIFAR-10 Batch 5:  Cost :0.42701, Accuracy on Training 0.9000 -Validation Accuracy: 0.6594\n",
      "Epoch 43, CIFAR-10 Batch 1:  Cost :0.49819, Accuracy on Training 0.8750 -Validation Accuracy: 0.6428\n",
      "Epoch 43, CIFAR-10 Batch 2:  Cost :0.37620, Accuracy on Training 0.9000 -Validation Accuracy: 0.6514\n",
      "Epoch 43, CIFAR-10 Batch 3:  Cost :0.34376, Accuracy on Training 0.9000 -Validation Accuracy: 0.6694\n",
      "Epoch 43, CIFAR-10 Batch 4:  Cost :0.44331, Accuracy on Training 0.9000 -Validation Accuracy: 0.6690\n",
      "Epoch 43, CIFAR-10 Batch 5:  Cost :0.41930, Accuracy on Training 0.9500 -Validation Accuracy: 0.6452\n",
      "Epoch 44, CIFAR-10 Batch 1:  Cost :0.53487, Accuracy on Training 0.8250 -Validation Accuracy: 0.6498\n",
      "Epoch 44, CIFAR-10 Batch 2:  Cost :0.34699, Accuracy on Training 0.9250 -Validation Accuracy: 0.6662\n",
      "Epoch 44, CIFAR-10 Batch 3:  Cost :0.33744, Accuracy on Training 0.9500 -Validation Accuracy: 0.6680\n",
      "Epoch 44, CIFAR-10 Batch 4:  Cost :0.41342, Accuracy on Training 0.9250 -Validation Accuracy: 0.6570\n",
      "Epoch 44, CIFAR-10 Batch 5:  Cost :0.39985, Accuracy on Training 0.9500 -Validation Accuracy: 0.6668\n",
      "Epoch 45, CIFAR-10 Batch 1:  Cost :0.47487, Accuracy on Training 0.8000 -Validation Accuracy: 0.6602\n",
      "Epoch 45, CIFAR-10 Batch 2:  Cost :0.32319, Accuracy on Training 0.9000 -Validation Accuracy: 0.6664\n",
      "Epoch 45, CIFAR-10 Batch 3:  Cost :0.32367, Accuracy on Training 0.8750 -Validation Accuracy: 0.6662\n",
      "Epoch 45, CIFAR-10 Batch 4:  Cost :0.36959, Accuracy on Training 0.9500 -Validation Accuracy: 0.6684\n",
      "Epoch 45, CIFAR-10 Batch 5:  Cost :0.37161, Accuracy on Training 0.9500 -Validation Accuracy: 0.6620\n",
      "Epoch 46, CIFAR-10 Batch 1:  Cost :0.46184, Accuracy on Training 0.8250 -Validation Accuracy: 0.6530\n",
      "Epoch 46, CIFAR-10 Batch 2:  Cost :0.34333, Accuracy on Training 0.9000 -Validation Accuracy: 0.6594\n",
      "Epoch 46, CIFAR-10 Batch 3:  Cost :0.31768, Accuracy on Training 0.9250 -Validation Accuracy: 0.6670\n",
      "Epoch 46, CIFAR-10 Batch 4:  Cost :0.37117, Accuracy on Training 0.9500 -Validation Accuracy: 0.6712\n",
      "Epoch 46, CIFAR-10 Batch 5:  Cost :0.35394, Accuracy on Training 0.9500 -Validation Accuracy: 0.6698\n",
      "Epoch 47, CIFAR-10 Batch 1:  Cost :0.51309, Accuracy on Training 0.8250 -Validation Accuracy: 0.6566\n",
      "Epoch 47, CIFAR-10 Batch 2:  Cost :0.33833, Accuracy on Training 0.9500 -Validation Accuracy: 0.6552\n",
      "Epoch 47, CIFAR-10 Batch 3:  Cost :0.33813, Accuracy on Training 0.9250 -Validation Accuracy: 0.6726\n",
      "Epoch 47, CIFAR-10 Batch 4:  Cost :0.39286, Accuracy on Training 0.9250 -Validation Accuracy: 0.6614\n",
      "Epoch 47, CIFAR-10 Batch 5:  Cost :0.36978, Accuracy on Training 0.9250 -Validation Accuracy: 0.6762\n",
      "Epoch 48, CIFAR-10 Batch 1:  Cost :0.48643, Accuracy on Training 0.8500 -Validation Accuracy: 0.6678\n",
      "Epoch 48, CIFAR-10 Batch 2:  Cost :0.33089, Accuracy on Training 0.9250 -Validation Accuracy: 0.6630\n",
      "Epoch 48, CIFAR-10 Batch 3:  Cost :0.28802, Accuracy on Training 0.9500 -Validation Accuracy: 0.6752\n",
      "Epoch 48, CIFAR-10 Batch 4:  Cost :0.38649, Accuracy on Training 0.9500 -Validation Accuracy: 0.6632\n",
      "Epoch 48, CIFAR-10 Batch 5:  Cost :0.38580, Accuracy on Training 0.9500 -Validation Accuracy: 0.6678\n",
      "Epoch 49, CIFAR-10 Batch 1:  Cost :0.47474, Accuracy on Training 0.8500 -Validation Accuracy: 0.6664\n",
      "Epoch 49, CIFAR-10 Batch 2:  Cost :0.35187, Accuracy on Training 0.8750 -Validation Accuracy: 0.6696\n",
      "Epoch 49, CIFAR-10 Batch 3:  Cost :0.29872, Accuracy on Training 0.9000 -Validation Accuracy: 0.6602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49, CIFAR-10 Batch 4:  Cost :0.36665, Accuracy on Training 0.9500 -Validation Accuracy: 0.6728\n",
      "Epoch 49, CIFAR-10 Batch 5:  Cost :0.33859, Accuracy on Training 0.9250 -Validation Accuracy: 0.6734\n",
      "Epoch 50, CIFAR-10 Batch 1:  Cost :0.43789, Accuracy on Training 0.8500 -Validation Accuracy: 0.6678\n",
      "Epoch 50, CIFAR-10 Batch 2:  Cost :0.33472, Accuracy on Training 0.9250 -Validation Accuracy: 0.6704\n",
      "Epoch 50, CIFAR-10 Batch 3:  Cost :0.29145, Accuracy on Training 0.9500 -Validation Accuracy: 0.6622\n",
      "Epoch 50, CIFAR-10 Batch 4:  Cost :0.36762, Accuracy on Training 0.9500 -Validation Accuracy: 0.6722\n",
      "Epoch 50, CIFAR-10 Batch 5:  Cost :0.34791, Accuracy on Training 0.9500 -Validation Accuracy: 0.6688\n"
     ]
    }
   ],
   "source": [
    "save_model_path = 'D:\\Study\\Deep_Learning\\image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "                \n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from D:\\Study\\Deep_Learning\\image_classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from D:\\Study\\Deep_Learning\\image_classification\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.65595703125\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = 'D:\\Study\\Deep_Learning\\image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 5\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_testing.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
